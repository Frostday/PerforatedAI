{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Base Network"
      ],
      "metadata": {
        "id": "0Mz8EdGqcu5S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awBJpmyfcBFJ"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "def get_dataloaders(batch_size=16, val_frac=0.1):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "    trainset_full = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    val_size = int(len(trainset_full) * val_frac)\n",
        "    train_size = len(trainset_full) - val_size\n",
        "    trainset, valset = random_split(trainset_full, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    return trainloader, valloader, testloader\n",
        "\n",
        "def accuracy(outputs, targets):\n",
        "    preds = outputs.argmax(dim=1)\n",
        "    return (preds == targets).float().mean().item()\n",
        "\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss, running_acc, n = 0.0, 0.0, 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        bs = labels.size(0)\n",
        "        running_loss += loss.item() * bs\n",
        "        running_acc += accuracy(outputs, labels) * bs\n",
        "        n += bs\n",
        "    return running_loss / n, running_acc / n\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss, running_acc, n = 0.0, 0.0, 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        bs = labels.size(0)\n",
        "        running_loss += loss.item() * bs\n",
        "        running_acc += accuracy(outputs, labels) * bs\n",
        "        n += bs\n",
        "    return running_loss / n, running_acc / n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')\n",
        "\n",
        "trainloader, valloader, testloader = get_dataloaders(batch_size=16, val_frac=0.1)\n",
        "\n",
        "model = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "\n",
        "best_val_acc = 0.0\n",
        "best_path = 'best_cifar10_baseline.pt'\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(1, epochs + 1):\n",
        "    tr_loss, tr_acc = train_one_epoch(model, trainloader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = evaluate(model, valloader, criterion, device)\n",
        "    print(f'Epoch {epoch:02d} | train_loss={tr_loss:.4f} | train_acc={tr_acc:.4f} | val_loss={val_loss:.4f} | val_acc={val_acc:.4f}')\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save({'model_state': model.state_dict()}, best_path)\n",
        "\n",
        "ckpt = torch.load(best_path, map_location=device)\n",
        "model.load_state_dict(ckpt['model_state'])\n",
        "te_loss, te_acc = evaluate(model, testloader, criterion, device)\n",
        "print(f'Test: loss={te_loss:.4f} | acc={te_acc:.4f} ({te_acc*100:.2f}%)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toXl5LjOg-MC",
        "outputId": "89f836f9-70bf-46d9-d8f9-377b84090cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train_loss=2.0337 | train_acc=0.2483 | val_loss=1.7392 | val_acc=0.3590\n",
            "Epoch 02 | train_loss=1.5581 | train_acc=0.4286 | val_loss=1.5053 | val_acc=0.4570\n",
            "Epoch 03 | train_loss=1.4019 | train_acc=0.4920 | val_loss=1.3418 | val_acc=0.5138\n",
            "Epoch 04 | train_loss=1.2919 | train_acc=0.5360 | val_loss=1.2673 | val_acc=0.5454\n",
            "Epoch 05 | train_loss=1.2089 | train_acc=0.5683 | val_loss=1.2597 | val_acc=0.5474\n",
            "Epoch 06 | train_loss=1.1408 | train_acc=0.5914 | val_loss=1.1381 | val_acc=0.5974\n",
            "Epoch 07 | train_loss=1.0858 | train_acc=0.6169 | val_loss=1.1249 | val_acc=0.6014\n",
            "Epoch 08 | train_loss=1.0324 | train_acc=0.6344 | val_loss=1.0874 | val_acc=0.6076\n",
            "Epoch 09 | train_loss=0.9910 | train_acc=0.6497 | val_loss=1.0575 | val_acc=0.6312\n",
            "Epoch 10 | train_loss=0.9484 | train_acc=0.6639 | val_loss=1.0469 | val_acc=0.6314\n",
            "Epoch 11 | train_loss=0.9102 | train_acc=0.6776 | val_loss=1.0304 | val_acc=0.6394\n",
            "Epoch 12 | train_loss=0.8719 | train_acc=0.6935 | val_loss=1.0685 | val_acc=0.6246\n",
            "Epoch 13 | train_loss=0.8419 | train_acc=0.7030 | val_loss=1.0400 | val_acc=0.6394\n",
            "Epoch 14 | train_loss=0.8078 | train_acc=0.7150 | val_loss=1.0321 | val_acc=0.6470\n",
            "Epoch 15 | train_loss=0.7805 | train_acc=0.7236 | val_loss=1.0277 | val_acc=0.6472\n",
            "Epoch 16 | train_loss=0.7482 | train_acc=0.7360 | val_loss=1.0777 | val_acc=0.6370\n",
            "Epoch 17 | train_loss=0.7252 | train_acc=0.7438 | val_loss=1.0570 | val_acc=0.6370\n",
            "Epoch 18 | train_loss=0.6952 | train_acc=0.7553 | val_loss=1.0653 | val_acc=0.6474\n",
            "Epoch 19 | train_loss=0.6717 | train_acc=0.7616 | val_loss=1.0827 | val_acc=0.6420\n",
            "Epoch 20 | train_loss=0.6449 | train_acc=0.7700 | val_loss=1.0976 | val_acc=0.6444\n",
            "Test: loss=1.0695 | acc=0.6511 (65.11%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dendritic Network"
      ],
      "metadata": {
        "id": "soXPSJigcx0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PerforatedAI/PerforatedAI.git\n",
        "!cd PerforatedAI/ && pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbFRAI6ScXoU",
        "outputId": "ea82391c-4e9e-431d-80dd-acada2ffd2c5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'PerforatedAI' already exists and is not an empty directory.\n",
            "Obtaining file:///content/PerforatedAI\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from perforatedai==2.0.3) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from perforatedai==2.0.3) (0.23.0+cu126)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from perforatedai==2.0.3) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from perforatedai==2.0.3) (2.2.2)\n",
            "Requirement already satisfied: rsa in /usr/local/lib/python3.12/dist-packages (from perforatedai==2.0.3) (4.9.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from perforatedai==2.0.3) (6.0.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from perforatedai==2.0.3) (0.6.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->perforatedai==2.0.3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->perforatedai==2.0.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->perforatedai==2.0.3) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->perforatedai==2.0.3) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib->perforatedai==2.0.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->perforatedai==2.0.3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->perforatedai==2.0.3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->perforatedai==2.0.3) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->perforatedai==2.0.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->perforatedai==2.0.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->perforatedai==2.0.3) (2025.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa->perforatedai==2.0.3) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->perforatedai==2.0.3) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->perforatedai==2.0.3) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->perforatedai==2.0.3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->perforatedai==2.0.3) (3.0.3)\n",
            "Installing collected packages: perforatedai\n",
            "  Attempting uninstall: perforatedai\n",
            "    Found existing installation: perforatedai 2.0.3\n",
            "    Uninstalling perforatedai-2.0.3:\n",
            "      Successfully uninstalled perforatedai-2.0.3\n",
            "  Running setup.py develop for perforatedai\n",
            "Successfully installed perforatedai-2.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from perforatedai import globals_perforatedai as GPA\n",
        "from perforatedai import utils_perforatedai as UPA\n",
        "\n",
        "GPA.pc.set_testing_dendrite_capacity(False)"
      ],
      "metadata": {
        "id": "fXjYJn1MgWiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')\n",
        "\n",
        "trainloader, valloader, testloader = get_dataloaders(batch_size=16, val_frac=0.1)\n",
        "\n",
        "model = Net()\n",
        "model = UPA.initialize_pai(model)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "GPA.pai_tracker.set_optimizer(optim.SGD)\n",
        "optimArgs = {'params':model.parameters(), 'lr': 1e-3, 'momentum': 0.9}\n",
        "optimizer = GPA.pai_tracker.setup_optimizer(model, optimArgs)\n",
        "\n",
        "best_val_acc, best_path = 0.0, 'best_cifar10_pai.pt'\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    tr_loss, tr_acc = train_one_epoch(model, trainloader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = evaluate(model, valloader, criterion, device)\n",
        "\n",
        "    print(f'Epoch {epoch:02d} | train_loss={tr_loss:.4f} | train_acc={tr_acc:.4f} | val_loss={val_loss:.4f} | val_acc={val_acc:.4f}')\n",
        "\n",
        "    GPA.pai_tracker.add_extra_score(tr_acc, 'Train Accuracy')\n",
        "    GPA.pai_tracker.add_extra_score(tr_loss, 'Train Loss')\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save({'model_state': model.state_dict()}, best_path)\n",
        "\n",
        "    model, restructured, training_complete = GPA.pai_tracker.add_validation_score(val_acc, model)\n",
        "    model.to(device)\n",
        "    if training_complete:\n",
        "        print('PAI signaled training is complete.')\n",
        "        break\n",
        "    elif restructured:\n",
        "        optimArgs = {'params':model.parameters(), 'lr': 1e-3, 'momentum': 0.9}\n",
        "        optimizer = GPA.pai_tracker.setup_optimizer(model, optimArgs)\n",
        "\n",
        "# ckpt = torch.load(best_path, map_location=device)\n",
        "# model.load_state_dict(ckpt['model_state'])\n",
        "te_loss, te_acc = evaluate(model, testloader, criterion, device)\n",
        "print(f'Test: loss={te_loss:.4f} | acc={te_acc:.4f} ({te_acc*100:.2f}%)')\n",
        "GPA.pai_tracker.add_test_score(te_acc, 'Test Accuracy')\n",
        "GPA.pai_tracker.add_test_score(te_loss, 'Test Loss')"
      ],
      "metadata": {
        "id": "-iW8bPNDh7cW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jm48cgj4Ac_K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}